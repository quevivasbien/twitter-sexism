{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAACL_DATA = 'training_data/NAACL_revised.csv'\n",
    "training_data = pd.read_csv(NAACL_DATA, usecols=['label', 'text'])\n",
    "\n",
    "tweets = list(training_data.text)\n",
    "labels = np.array(training_data.label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, labels)\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      2060\n",
      "           1       0.89      0.35      0.50       738\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2798\n",
      "   macro avg       0.85      0.67      0.70      2798\n",
      "weighted avg       0.83      0.82      0.79      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('svm', SVC(gamma='scale', class_weight='balanced'))\n",
    "])\n",
    "\n",
    "%time svm_clf.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, svm_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 795 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      2060\n",
      "           1       0.73      0.75      0.74       738\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2798\n",
      "   macro avg       0.82      0.83      0.82      2798\n",
      "weighted avg       0.86      0.86      0.86      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bayes_clf = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('naive_bayes', ComplementNB(alpha=0.3))\n",
    "])\n",
    "\n",
    "%time bayes_clf.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, bayes_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.15 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      2060\n",
      "           1       0.84      0.55      0.67       738\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2798\n",
      "   macro avg       0.85      0.76      0.79      2798\n",
      "weighted avg       0.85      0.85      0.84      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_clf = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('adaboost', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "%time adaboost_clf.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, adaboost_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.13 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      2060\n",
      "           1       0.92      0.50      0.64       738\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2798\n",
      "   macro avg       0.88      0.74      0.78      2798\n",
      "weighted avg       0.86      0.86      0.84      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_clf = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=10))\n",
    "])\n",
    "\n",
    "%time rforest_clf.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, rforest_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.14 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2060\n",
      "           1       0.82      0.69      0.75       738\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      2798\n",
      "   macro avg       0.86      0.82      0.84      2798\n",
      "weighted avg       0.88      0.88      0.88      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_clf = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('clf', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('naive_bayes', ComplementNB(alpha=0.3)),\n",
    "            ('random_forest', RandomForestClassifier(n_estimators=10))\n",
    "        ],\n",
    "        voting='soft',\n",
    "        weights=[2,1]\n",
    "    ))\n",
    "])\n",
    "\n",
    "%time voting_clf.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, voting_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.44 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      2060\n",
      "           1       0.84      0.70      0.76       738\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2798\n",
      "   macro avg       0.87      0.83      0.84      2798\n",
      "weighted avg       0.88      0.89      0.88      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Found these (hopefully) optimized parameters with a GridSearchCV\n",
    "voting_clf = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('clf', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('naive_bayes', ComplementNB(alpha=0.1)),\n",
    "            ('random_forest', RandomForestClassifier(n_estimators=50))\n",
    "        ],\n",
    "        voting='soft',\n",
    "        weights=[1,1]\n",
    "    ))\n",
    "])\n",
    "\n",
    "%time voting_clf.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, voting_clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
