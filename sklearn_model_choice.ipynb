{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#local package\n",
    "import text_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "tweets, markers = text_processing.import_data('sexist_tweets.json', 'tweet_sample.json')\n",
    "#Separate into train and test sets\n",
    "train_x, validate_x, train_y, validate_y = model_selection.train_test_split(tweets, markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SET UP WORD FREQUENCY FEATURES\n",
    "\n",
    "# Word count w/CountVectorizer\n",
    "countVect = CountVectorizer(analyzer='word', tokenizer=text_processing.tokenize_status_text)\n",
    "countVect.fit(tweets)\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  countVect.transform(train_x)\n",
    "xvalid_count =  countVect.transform(validate_x)\n",
    "\n",
    "# word-level w/TfidfVectorizer\n",
    "tfidfVect = TfidfVectorizer(analyzer='word', max_features=5000,\n",
    "                            tokenizer=text_processing.tokenize_status_text)\n",
    "tfidfVect.fit(tweets)\n",
    "xtrain_tfidf =  tfidfVect.transform(train_x)\n",
    "xvalid_tfidf =  tfidfVect.transform(validate_x)\n",
    "\n",
    "# ngram-level w/TfidfVectorizer\n",
    "tfidfVect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_features=5000,\n",
    "                                   tokenizer=text_processing.tokenize_status_text)\n",
    "tfidfVect_ngram.fit(tweets)\n",
    "xtrain_tfidf_ngram =  tfidfVect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidfVect_ngram.transform(validate_x)\n",
    "\n",
    "# char-level w/TfidfVectorizer\n",
    "tfidfVect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=5000,\n",
    "                                         tokenizer=text_processing.tokenize_status_text)\n",
    "tfidfVect_ngram_chars.fit(tweets)\n",
    "xtrain_tfidf_ngram_chars =  tfidfVect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidfVect_ngram_chars.transform(validate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, validate_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.9673684210526315\n",
      "LR, WordLevel TF-IDF:  0.9596491228070175\n",
      "LR, N-Gram Vectors:  0.8785964912280702\n",
      "LR, CharLevel Vectors:  0.9568421052631579\n",
      "SVM, N-Gram Vectors:  0.7529824561403509\n",
      "RF, Count Vectors:  0.9385964912280702\n",
      "RF, WordLevel TF-IDF:  0.9547368421052631\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8548, 25960)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
