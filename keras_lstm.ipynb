{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for improvement:\n",
    "- Change hashing method so that the 5000 most common tokens are unique and all others are zero\n",
    "- Change random_tweets to be more random, and remove foreign languages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#local packages\n",
    "import twitter\n",
    "import text_processing\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "np.random.seed(152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tweet ids from hatespeech-master, filter for sexist tweets, and convert to a list\n",
    "tweet_ids = pd.read_csv('hatespeech-master/NAACL_SRW_2016.csv', header=None)\n",
    "tweet_ids = list(tweet_ids[tweet_ids[1] == 'sexism'][0])\n",
    "\n",
    "sexist_tweets = twitter.get_statuses(tweet_ids)\n",
    "sexist_tweet_text = [tweet['text'] for tweet in sexist_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now add a list of random tweets from random_tweets.csv\n",
    "random_tweets = list(pd.read_csv('random_tweets2.csv', header=None)[1])\n",
    "\n",
    "#Randomly select tweets from random_tweets so there are the same number as in sexist_tweets\n",
    "random_tweets = np.random.choice(random_tweets, len(sexist_tweet_text), replace=False).tolist()\n",
    "\n",
    "#Create a list of markers for sexist tweets:\n",
    "#0 = not sexist; 1 = sexist\n",
    "is_sexist = [1]*len(sexist_tweets) + [0]*len(random_tweets)\n",
    "\n",
    "#Concatenate the sexist and random tweets\n",
    "tweet_text = sexist_tweet_text + random_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_vector_length = 32\n",
    "\n",
    "#Convert words to integer hashes\n",
    "encoded_text = text_preprocessing.simple_hash(tweet_text, hashspace_size=vocab_size)\n",
    "#Pad word sequences so they're all the same length\n",
    "encoded_text = pad_sequences(encoded_text, padding='post')\n",
    "\n",
    "max_tweet_length = max([len(tw) for tw in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into training and validation sets\n",
    "\n",
    "#Use 25% of values as validation\n",
    "n = len(encoded_text)\n",
    "validation_indices = np.random.choice(n, size=(n // 4), replace=False)\n",
    "training_indices = np.setdiff1d(np.arange(n), validation_indices)\n",
    "\n",
    "X_train = np.array([encoded_text[i] for i in training_indices])\n",
    "y_train = np.array([is_sexist[i] for i in training_indices])\n",
    "X_test = np.array([encoded_text[i] for i in validation_indices])\n",
    "y_test = np.array([is_sexist[i] for i in validation_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4442 samples, validate on 1480 samples\n",
      "Epoch 1/2\n",
      "4442/4442 [==============================] - 14s 3ms/step - loss: 0.6939 - acc: 0.4975 - val_loss: 0.6932 - val_acc: 0.5020\n",
      "Epoch 2/2\n",
      "4442/4442 [==============================] - 14s 3ms/step - loss: 0.6935 - acc: 0.4881 - val_loss: 0.6932 - val_acc: 0.4980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ff89bb1be0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_tweet_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6932087453635963, 0.5]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save trained model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    if type(text) is str:\n",
    "        text = [text]\n",
    "    encoded = twitter.create_hash_indices(text, vocab_size)\n",
    "    encoded = pad_sequences(encoded, maxlen=max_tweet_length, padding='post')\n",
    "    return model.predict_classes(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sexist_tweet_text).to_csv('sexist_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
