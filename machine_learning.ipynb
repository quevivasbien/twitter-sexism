{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for improvement:\n",
    "- Change hashing method so that the 5000 most common tokens are unique and all others are zero\n",
    "- Change random_tweets to be more random, and remove foreign languages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import twitter\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tweet ids from hatespeech-master, filter for sexist tweets, and convert to a list\n",
    "tweet_ids = pd.read_csv('hatespeech-master/NAACL_SRW_2016.csv', header=None)\n",
    "tweet_ids = list(tweet_ids[tweet_ids[1] == 'sexism'][0])\n",
    "\n",
    "tweets = twitter.get_statuses(tweet_ids)\n",
    "tweet_text = [tweet['text'] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now add a list of random tweets from random_tweets.csv\n",
    "random_tweets = list(pd.read_csv('random_tweets.csv', header=None)[1])\n",
    "\n",
    "#Create a list of markers for sexist tweets:\n",
    "#0 = not sexist; 1 = sexist\n",
    "is_sexist = [0]*len(tweets) + [1]*len(random_tweets)\n",
    "\n",
    "#Concatenate the sexist and random tweets\n",
    "tweet_text += random_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_vector_length = 32\n",
    "\n",
    "#Convert words to integer hashes\n",
    "encoded_text = twitter.create_hash_indices(tweet_text, hashspace_size=vocab_size)\n",
    "#Pad word sequences so they're all the same length\n",
    "encoded_text = pad_sequences(encoded_text, padding='post')\n",
    "\n",
    "max_tweet_length = max([len(tw) for tw in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and validation sets\n",
    "\n",
    "np.random.seed(152)\n",
    "\n",
    "#Use 25% of values as validation\n",
    "n = len(encoded_text)\n",
    "validation_indices = np.random.choice(n, size=(n // 4), replace=False)\n",
    "training_indices = np.setdiff1d(np.arange(n), validation_indices)\n",
    "\n",
    "X_train = np.array([encoded_text[i] for i in training_indices])\n",
    "y_train = np.array([is_sexist[i] for i in training_indices])\n",
    "X_test = np.array([encoded_text[i] for i in validation_indices])\n",
    "y_test = np.array([is_sexist[i] for i in validation_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9544 samples, validate on 3181 samples\n",
      "Epoch 1/2\n",
      "9544/9544 [==============================] - 18s 2ms/step - loss: 0.5508 - acc: 0.7646 - val_loss: 0.5427 - val_acc: 0.7674\n",
      "Epoch 2/2\n",
      "9544/9544 [==============================] - 21s 2ms/step - loss: 0.5444 - acc: 0.7673 - val_loss: 0.5425 - val_acc: 0.7674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c186587fd0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_tweet_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5424987262279423, 0.7673687520210041]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save trained model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    if type(text) is str:\n",
    "        text = [text]\n",
    "    encoded = twitter.create_hash_indices(text, vocab_size)\n",
    "    encoded = pad_sequences(encoded, maxlen=max_tweet_length, padding='post')\n",
    "    return model.predict_classes(encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
